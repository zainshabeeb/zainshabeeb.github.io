<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Waleed Bin Khalid ‚Äî Robotics Engineer</title>
  <meta name="description" content="Robotics engineer focused on autonomy, vision, AI, control, and robot learning. Research and projects across legged robots, SLAM, reinforcement learning, and medical AI.">
  <meta name="theme-color" content="#0a3d62">
  <link rel="icon" href="images/favicon/favicon.ico" sizes="any">
  <link rel="dns-prefetch" href="//www.youtube.com">
  <link rel="preconnect" href="https://www.youtube.com" crossorigin>
  <link rel="dns-prefetch" href="//i.ytimg.com">
  <link rel="preconnect" href="https://i.ytimg.com" crossorigin>
  <link rel="dns-prefetch" href="//drive.google.com">
  <link rel="preconnect" href="https://drive.google.com" crossorigin>
  <link rel="dns-prefetch" href="//www.linkedin.com">
  <link rel="preconnect" href="https://www.linkedin.com" crossorigin>
  <link rel="dns-prefetch" href="//scholar.google.com">
  <link rel="preconnect" href="https://scholar.google.com" crossorigin>
  <link rel="stylesheet" href="styles.min.css">
  <script defer src="main.min.js"></script>

  <meta property="og:title" content="Waleed Bin Khalid ‚Äî Robotics Engineer">
  <meta property="og:description" content="Research, publications, and projects in robot autonomy, vision, AI, and control.">
  <meta property="og:type" content="website">
  <meta property="og:url" content="">
  <meta property="og:image" content="images/portfolioCaliImage.jpeg">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Waleed Bin Khalid ‚Äî Robotics Engineer">
  <meta name="twitter:description" content="Research, publications, and projects in robot autonomy, vision, AI, and control.">
  <meta name="twitter:image" content="images/portfolioCaliImage.jpeg">

  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Person",
    "name": "Waleed Bin Khalid",
    "jobTitle": "Robotics Engineer",
    "url": "",
    "image": "images/portfolioCaliImage.jpeg",
    "alumniOf": [
      {"@type": "CollegeOrUniversity", "name": "Georgia Institute of Technology"},
      {"@type": "CollegeOrUniversity", "name": "Habib University"}
    ],
    "sameAs": [
      "mailto:waleedbink1999@gmail.com",
      "https://www.linkedin.com/in/wbk999/",
      "https://scholar.google.com/citations?user=OYBEPc8AAAAJ&hl=en"
    ]
  }
  </script>
  </head>
  <body>
  <a class="skip-link" href="#main">Skip to main content</a>

  <header class="site-header" role="banner">
    <nav class="top-nav" aria-label="Primary">
      <a class="brand" href="#about" aria-label="Go to About">Waleed Bin Khalid</a>
<ul>
  <li><a href="#about" data-nav>About</a></li>
  <li><a href="#research" data-nav>Research Experience</a></li>
  <li><a href="#projects" data-nav>Academic Projects</a></li>
  <li><a href="#reflections" data-nav>Research Paper Reflections</a></li>
  <li><a href="#internships" data-nav>Work Experience</a></li>
  <li><a href="#teaching" data-nav>Teaching Experience</a></li>
  <li><a href="#education" data-nav>Education</a></li>
</ul>

    </nav>
  </header>

  <div class="layout">
    <aside class="sidebar" aria-labelledby="name-heading">
      <!-- <h1 id="name-heading">Waleed Bin Khalid</h1>
      <p class="tagline">Robotics Engineer ‚Ä¢ Autonomy, Vision, AI, Control</p> -->

      <div class="avatar">
        <img src="images/portfolioCaliImage.jpeg" srcset="images/portfolioCaliImage.jpeg 600w, images/portfolioCaliImage.jpeg 1200w" sizes="(max-width: 800px) 100vw, 320px" alt="Portrait of Waleed Bin Khalid" loading="lazy" decoding="async">
      </div>

      <div class="social" aria-label="Contact and social links">
        <a href="mailto:waleedbink1999@gmail.com" class="icon-btn" aria-label="Email">
          <svg viewBox="0 0 24 24" aria-hidden="true"><path d="M20 4H4a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2Zm0 4-8 5L4 8V6l8 5 8-5Z"/></svg>
        </a>
        <a href="https://www.linkedin.com/in/wbk999/" class="icon-btn" aria-label="LinkedIn" target="_blank" rel="noopener">
          <svg viewBox="0 0 24 24" aria-hidden="true"><path d="M6.94 6.5A2.44 2.44 0 1 1 4.5 4.06 2.44 2.44 0 0 1 6.94 6.5ZM7 8.98H4V20h3V8.98Zm6.5-.27c-2.01 0-3.33 1.06-3.88 2.08h-.06V9H6.5V20h3.06v-5.8c0-1.46.28-2.88 2.09-2.88 1.77 0 1.8 1.66 1.8 2.98V20H16.5v-6.3c0-3.24-1.73-4.99-3.99-4.99Z"/></svg>
        </a>
        <a href="https://scholar.google.com/citations?user=OYBEPc8AAAAJ&hl=en" class="icon-btn" aria-label="Google Scholar" target="_blank" rel="noopener">
          <svg viewBox="0 0 24 24" aria-hidden="true"><path d="M12 3 2 9l10 6 8-4.8V17h2V9L12 3Zm0 8.2L6.47 8.2 12 5l5.53 3.2L12 11.2ZM6 19h12v2H6z"/></svg>
                      </a>
                    </div>

      <section class="affiliations" aria-label="Past affiliations">
        <h2 class="sr-only">Past affiliations</h2>
        <ul class="affiliations">
          <li class="row">
            <a href="https://habib.edu.pk/" target="_blank" rel="noopener"><img src="images/hu logo.png" alt="Habib University logo" loading="lazy" decoding="async"></a>
            <a href="https://www.gatech.edu/" target="_blank" rel="noopener"><img src="images/gt logo.png" alt="Georgia Tech logo" loading="lazy" decoding="async"></a>
            <a href="https://www.aku.edu/Pages/home.aspx" target="_blank" rel="noopener"><img src="images/aku logo.png" alt="Aga Khan University Hospital logo" loading="lazy" decoding="async"></a>
            <a href="https://epic.gatech.edu/" target="_blank" rel="noopener"><img src="images/epic lab logo.png" alt="EPIC Lab logo" loading="lazy" decoding="async"></a>
          </li>
          <li class="row">
            <a href="https://faculty.cc.gatech.edu/~sha9/" target="_blank" rel="noopener"><img src="images/ha lab logo.png" alt="Ha Lab logo" loading="lazy" decoding="async"></a>
            <a href="https://thisisborderless.com/" target="_blank" rel="noopener"><img src="images/borderless-logo.png" alt="Borderless logo" loading="lazy" decoding="async"></a>
          </li>
        </ul>
      </section>

      <div class="cv-section" style="text-align: center; margin-top: 1.5rem;">
        <div style="margin-bottom: 0.5rem;">
          <a href="https://drive.google.com/file/d/1UQusXln7YdwfZX6s2aJkz5exkUGIcPxx/view?usp=sharing" target="_blank" rel="noopener" style="color: var(--accent); text-decoration: none; margin-right: 1rem;">CV</a>
          <span style="color: var(--muted);">/</span>
          <a href="https://drive.google.com/file/d/1Oi9zwG-eZKEef6s6rT1qk_Ve09aAy1vb/view?usp=sharing" target="_blank" rel="noopener" style="color: var(--accent); text-decoration: none; margin-left: 1rem;">Resume</a>
        </div>
        <p style="font-size: 0.85rem; color: var(--muted);">
          Last Updated: 6th September 2025
        </p>
      </div>
    </aside>

    <main id="main" tabindex="-1">
      <section id="about" class="card" aria-labelledby="about-heading">
        <h2 id="about-heading">About</h2>
        <p>I'm a Robotics Engineer who is excited about a world where robots and humans coexist and cooperate across a variety of tasks, boosting productivity, safety, and efficiency. My research interests center on <strong>robot autonomy</strong>, with a particular focus on embodied AI, robot learning, perception, and control theory. I also hold a keen interest in AI methods and applying machine learning to real-world problems across different domains.</p>

<p>I completed my M.S. in Robotics from the <strong>Georgia Institute of Technology</strong>, Atlanta, GA, USA, and my B.S. in Electrical Engineering with double minors in Physics and Mathematics from <strong>Habib University</strong>, Karachi, Pakistan.</p>

<p>Beyond technology, I love to travel solo ‚úàÔ∏è, capture moments through photography üì∏, and try out new sports üèìüèä. I'm also a passionate cricket fan üèè, enjoy playing cards ‚ô†Ô∏è, and have recently developed an interest in chess ‚ôüÔ∏è.</p>
<p>‚û°Ô∏è Scroll down to learn more about my past research work, academics, teaching, and professional work experience.</p>
      </section>

      <section id="research" class="card" aria-labelledby="research-heading">
        <h2 id="research-heading">Research & Publications</h2>

        <article class="entry" data-tags="Robotics RL">
          <header>
            <h3 class="entry-title">Legged Robot Navigation in Uncertain Terrains using Deep Reinforcement Learning</h3>
            <p class="entry-meta"><em>Georgia Institute of Technology ¬∑ Research Project</em></p>
          </header>
          <p>Developed a dynamic, vectorized RaiSim environment and integrated deep reinforcement learning (PyTorch) to train a navigation policy on top of a low-level locomotion controller. Designed custom rewards to optimize point-to-goal navigation. Created diverse terrains and explored motion planning (RRT, A*) and dataset generation for imitation learning. Gained expertise in robot kinematics and frame transformations for legged robots.</p>
          <!-- <div class="media-row">
            <figure>
              <img src="images/capstone proj report.png" srcset="images/capstone proj report.png 300w, images/capstone proj report.png 600w" sizes="(max-width: 700px) 45vw, 300px" width="300" height="200" alt="Cover thumbnail of the legged robot navigation report" loading="lazy" decoding="async">
              <figcaption>Project Report</figcaption>
            </figure>
          </div> -->
          <div class="media-row">
            <figure>
              <iframe src="https://drive.google.com/file/d/1V7_6QbQywA20UvEP3XbFfvrYVioojA_F/preview" width="300" height="200" loading="lazy" title="Lateral view video" allow="autoplay"></iframe>
              <figcaption>Video 1</figcaption>
            </figure>
            <figure>
              <iframe src="https://drive.google.com/file/d/1V88QNcGsLN44wQ76EdNuBSbziz7VqR5I/preview" width="300" height="200" loading="lazy" title="Top view video" allow="autoplay"></iframe>
              <figcaption>Video 2</figcaption>
            </figure>
          </div>
          <div class="resources" aria-label="Resources">
            <a class="resource" href="https://drive.google.com/file/d/1VOAhbj0JYWm-aivxUDTKNbys2pnibXPD/view?usp=sharing" target="_blank" rel="noopener" aria-label="Open project report in Google Drive"><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 3v2h3.59L7 15.59 8.41 17 19 6.41V10h2V3z"/><path d="M5 5h5V3H3v7h2z"/></svg><span>Project Report</span></a>

          </div>
        </article>

        <article class="entry" data-tags="CV Medicine">
          <header>
            <h3 class="entry-title">An AI Model for Instance Segmentation and Tooth Numbering on Orthopantomograms</h3>
            <p class="entry-meta"><em>International Journal of Computerized Dentistry (2023)</em> ¬∑ Niha Adnan, Waleed Bin Khalid, Fahad Umer</p>
          </header>
          <p>Worked with a team of dentists at one of the leading hospitals in Pakistan to develop a deep-learning pipeline for teeth segmentation and labeling using U-NET and FRCNN. An Orthopantomograms (OPGs) dataset was self-annotated & processed for the project using PIL, numpy, JSON & OpenCV.</p>
          <div class="media-row">
            <figure>
              <img src="images/5 - mask.png" srcset="images/5 - mask.png 300w, images/5 - mask.png 600w" sizes="(max-width: 700px) 45vw, 300px" alt="Ground-truth tooth segmentation mask" loading="lazy" decoding="async">
              <figcaption>Ground-truth Mask</figcaption>
            </figure>
            <figure>
              <img src="images/tooth seg.jpeg" srcset="images/tooth seg.jpeg 300w, images/tooth seg.jpeg 600w" sizes="(max-width: 700px) 45vw, 300px" alt="Visualization of instance segmentation of teeth" loading="lazy" decoding="async">
              <figcaption>Instance Segmentation</figcaption>
            </figure>
            <figure>
              <img src="images/obj detect.jpeg" srcset="images/obj detect.jpeg 300w, images/obj detect.jpeg 600w" sizes="(max-width: 700px) 45vw, 300px" alt="Teeth detection and numeric labeling visualization" loading="lazy" decoding="async">
              <figcaption>Detection & Labels</figcaption>
            </figure>
          </div>
          <div class="resources">
            <a class="resource" href="https://europepmc.org/article/med/36705317" target="_blank" rel="noopener" aria-label="View the full publication">
              <svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 3v2h3.59L7 15.59 8.41 17 19 6.41V10h2V3z"/><path d="M5 5h5V3H3v7h2z"/></svg><span>Publication</span>
            </a>
          </div>
        </article>

        <article class="entry" data-tags="Robotics Medicine">
          <header>
            <h3 class="entry-title">Contactless Vitals Measurement Robot</h3>
            <p class="entry-meta"><em>ICARA (2022)</em> ¬∑ Waleed Bin Khalid, Amna Anwar, Owais Talaat Waheed</p>
          </header>
          <p>Designed and developed a contactless vitals measurement robot equipped with an Ackermann drive for my undergraduate final year project. The robot utilised a camera, machine learning, and signal processing to measure vitals and decrease medical staff contact time with contagious patients. The system reported around 70% accuracy for Blood Pressure, and 90% for Heart Rate, Oxygen Saturation, and Temperature. I presented the work as the first author at ICARA 2022 and received the Best Capstone Project award for this work.</p>
          <div class="media-row">
            <!-- <figure>
              <img src="images/contactless vitals thesis pic.png" srcset="images/contactless vitals thesis pic.png 300w, images/contactless vitals thesis pic.png 600w" sizes="(max-width: 700px) 45vw, 300px" alt="Thumbnail of contactless vitals thesis document" loading="lazy" decoding="async">
              <figcaption>Thesis</figcaption>
            </figure>
            <figure>
              <img src="images/ieeePageDisplay.png" srcset="images/ieeePageDisplay.png 300w, images/ieeePageDisplay.png 600w" sizes="(max-width: 700px) 45vw, 300px" alt="IEEE publication page thumbnail" loading="lazy" decoding="async">
              <figcaption>IEEE Article</figcaption>
            </figure> -->
            <!-- <figure>
              <img src="images/contactless vitals measurement design.png" srcset="images/contactless vitals measurement design.png 300w, images/contactless vitals measurement design.png 600w" sizes="(max-width: 700px) 45vw, 300px" alt="Design diagram of the contactless vitals measurement robot" loading="lazy" decoding="async">
              <figcaption>Design</figcaption>
            </figure> -->
          </div>
          <div class="media-row">
            <figure>
              <iframe src="https://www.youtube.com/embed/yuYqhCQHWI4" width="300" height="200" loading="lazy" title="Data collection video" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"></iframe>
              <figcaption>Video</figcaption>
            </figure>
          </div>
          <div class="resources">
            <a class="resource" href="https://drive.google.com/file/d/1dmpo7BZbzWkDmhA3sYa2WLOv3P7I_K-t/view?usp=sharing" target="_blank" rel="noopener" aria-label="Open full thesis in Google Drive"><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 3v2h3.59L7 15.59 8.41 17 19 6.41V10h2V3z"/><path d="M5 5h5V3H3v7h2z"/></svg><span>Thesis</span></a>
            <a class="resource" href="https://ieeexplore.ieee.org/document/9738523" target="_blank" rel="noopener" aria-label="Open IEEE publication"><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 3v2h3.59L7 15.59 8.41 17 19 6.41V10h2V3z"/><path d="M5 5h5V3H3v7h2z"/></svg><span>Publication</span></a>
          </div>
        </article>
      </section>



      <section id="projects" class="card" aria-labelledby="projects-heading">
        <h2 id="projects-heading">Projects</h2>


        <article class="entry" data-tags="Robotics RL">
          <header>
            <h3 class="entry-title">TAMP for Mobile Manipulation using Perception, LLMs and Motion Planning.</h3>
            <p class="entry-meta"><em>LLMs, Task and Motion Planning (TAMP), Kinematics, Perception, PyBullet Simulation</em></p>

          </header>
          <p>Building a bottom-up simulation framework for mobile manipulation in PyBullet, to study and understand Task and Motion Planning (TAMP) for robotic systems like a mobile manipulator. A Clearpath Husky base with a Franka Panda arm executes multi-step language instructions by combining LLM-based task planning with end-effector camera perception and IK motion execution. The system successfully achieves reliable single-cube picks and two-cube stacking, while multi-cube stacking reveals challenges such as motion smoothness, base drift, and grasp retries. This ongoing project not only demonstrates the integration of symbolic task planning with continuous control but also serves as a platform to study richer perception, collision-aware motion planning, feedback-driven correction, and vision‚Äìlanguage grounding to push toward general-purpose mobile manipulation.</p>
          <p class="entry-meta"><em> This project is currently ongoing and further updates will be made as I progress.</em></p>

              

          <div class="media-row">
            <figure>
              <iframe src="https://drive.google.com/file/d/1r0ry48lVDTxldfucFRYnrUPfph0bc30e/preview" width="300" height="200" loading="lazy" title="Project video 1" allow="autoplay"></iframe>
              <figcaption>Demo videos of picking single cube and stacking 2 cubes</figcaption>
            </figure>
            <figure>
              <img src="images/mobile2.png" srcset="images/mobile2.png 300w, images/mobile2.png 200w" width="200" height="80" sizes="(max-width: 700px) 45vw, 300px" alt="mobile 2" loading="lazy" decoding="async">
              <figcaption>Husky + Franka Emika Arm platform</figcaption>
            </figure>
          </div>
          <div class="resources" aria-label="Resources">
            <a class="resource" href="https://drive.google.com/file/d/1rgxZqGLinkX4re_l5X6LzL0JNABEn9aZ/view?usp=sharing" target="_blank" rel="noopener" aria-label="Open project report in Google Drive"><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 3v2h3.59L7 15.59 8.41 17 19 6.41V10h2V3z"/><path d="M5 5h5V3H3v7h2z"/></svg><span>Initial Report</span></a>
          </div>

        </article>









        <article class="entry" data-tags="CV Robotics">
          <header>
            <h3 class="entry-title">LLM-Based Path Planning in Grid Worlds: Local and Global Policies vs A* Baseline</h3>
            <p class="entry-meta"><em> LLMs, A* Search, Hybrid Planning, Grid Navigation </em></p>
          </header>
          <p>Working on this project to understand and study how LLMs can be used for path planning. Current findings are that vanilla local policies achieve around 60% success on A*-solvable cases, while vanilla global one-shot planning reaches only about 25% and degrades more quickly as obstacle density increases. These initial results highlight the relative resilience of local prompting, but the work remains ongoing. I am systematically exploring improvements through richer local contexts (e.g., 5√ó5 windows, clearance features), prompt refinements (few-shots, ranking), and hybridization with classical priors (subgoal induction, A* cost-to-go). The broader goal is to examine how far prompt engineering and minimal feature additions can push LLM-based planning toward reliable performance, and to assess the feasibility of such methods for robotic path planning in more realistic settings.</p>
          <p class="entry-meta"><em> This project is currently ongoing and further updates will be made as I progress.</em></p>

          <div class="media-row" style="display:block;">
            <figure style="margin-bottom: 2em;">
              <img src="images/comparison_21.png"
                   srcset="images/comparison_21.png 300w, images/comparison_21.png 600w"
                   sizes="(max-width: 700px) 90vw, 600px"
                   alt="Comparison of Global, Local and A* Policy with 21 random obstacles"
                   loading="lazy" decoding="async">
              <figcaption>Comparison of Global, Local and A* Policy with 21 random obstacles</figcaption>
            </figure>
          
            <figure style="margin-bottom: 2em;">
              <img src="images/summary_dual.png"
                   srcset="images/summary_dual.png 300w, images/summary_dual.png 600w"
                   sizes="(max-width: 700px) 90vw, 600px"
                   alt="Aggregate Results Summary"
                   loading="lazy" decoding="async">
              <figcaption>Aggregate Results Summary</figcaption>
            </figure>
          </div>
          
          <div class="resources">
            <a class="resource" href="https://drive.google.com/file/d/1nLylP_ADnhbF5E9aqVWqI_i2cX0_MuyO/view?usp=sharing" target="_blank" rel="noopener" aria-label="Open project report"><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 3v2h3.59L7 15.59 8.41 17 19 6.41V10h2V3z"/><path d="M5 5h5V3H3v7h2z"/></svg><span>Initial Report</span></a>
          </div>
        </article>


        <article class="entry" data-tags="Robotics RL">
          <header>
            <h3 class="entry-title">Motion Planning for 3-Link Robot Arm</h3>
            <p class="entry-meta"><em>RRT, Forward and Inverse Kinematics, PID, PyGame</em></p>
          </header>
          <p>Implemented RRT from scratch with custom collision detection conditions to move a 3 link arm in the presence of obstacles and walls. Simulated the environment and robot using PyGame and tuned RRT and PID parameters for optimal performance in varying configerations. Implemented the forward and inverse kinematics from scratch to compute path variables. Created multiple demos, to show different aspects such as wrist limitations, reachable space considerations, and RRT performance.</p>
          
              

          <div class="media-row">
            <figure>
              <iframe src="https://drive.google.com/file/d/1DMkUcLMCuf9Du0XBSZsFXjX6xKAv4m9P/preview" width="300" height="200" loading="lazy" title="Project video 1" allow="autoplay"></iframe>
              <figcaption>Video 1</figcaption>
            </figure>
            <figure>
              <iframe src="https://drive.google.com/file/d/1eEWxbQ86DElDh5YCCFBxD5U2d-hK9GD8/preview" width="300" height="200" loading="lazy" title="Project video 2" allow="autoplay"></iframe>
              <figcaption>Video 2</figcaption>
            </figure>
          </div>
          <div class="resources" aria-label="Resources">
            <a class="resource" href="https://drive.google.com/file/d/1-w0aCibfOu3rsvo1NARajqhJBNuo_Cs2/preview" target="_blank" rel="noopener" aria-label="Open project report in Google Drive"><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 3v2h3.59L7 15.59 8.41 17 19 6.41V10h2V3z"/><path d="M5 5h5V3H3v7h2z"/></svg><span>Project Report</span></a>
          </div>

        </article>

        <article class="entry" data-tags="Robotics CV">
          <header>
            <h3 class="entry-title">Robot Maze Navigation for Variable Maze Structures</h3>
            <p class="entry-meta"><em>CNNs, ROS 2, Path Planning</em></p>
          </header>
          <p>Tackled the challenge of navigating an unknown maze by implementing a combination of the Bug algorithm, collision avoidance, and CNN-based image classification to create a solution invariant to the maze structure, starting point, and end point. Optimized a CNN to detect signs with 99% accuracy by augmenting for invariance and extensively preprocessing the data. The motion plan integrated CNN-generated maneuvering commands, lidar-based wall detection for collision avoidance, the Bug algorithm as a fallback, and PID control to ensure accurate straight-line movement and sharp turns, achieving 100% navigation success.</p>
          
          
          
          
          <div class="media-row">
            <figure>
              <iframe src="https://drive.google.com/file/d/1b4P67eACJC3HYH3cS7nW_fX0XIY0ffdR/preview" width="400" height="300" loading="lazy" title="Maze navigation video" allow="autoplay"></iframe>
              <figcaption>Video</figcaption>
            </figure>
        
          </div>

         
          
<!--           
          
        </article>
        <article class="entry" data-tags="Robotics CV">
          <header>
            <h3 class="entry-title">Manipulator Trajectory Planning and Control</h3>
            <p class="entry-meta"><em>Control, Manipulators, MATLAB, ME 6407 @ Georgia Tech Course Work</em></p>
          </header>
          <p>Designed a trajectory for a 3-DOF robot to follow a circle in 2D while keeping end-effector perpendicularity, using a quartic polynomial. Applied a transpose-Jacobian controller for joint torque control on a 3-DOF manipulator (with gravity compensation) to achieve precise
            end-effector tasks, such as drawing geometric patterns and letters on a 2D plane.</p>  
          <div class="media-row">
            <figure>
              <iframe src="https://drive.google.com/file/d/1b4P67eACJC3HYH3cS7nW_fX0XIY0ffdR/preview" width="400" height="300" loading="lazy" title="Maze navigation video" allow="autoplay"></iframe>
              <figcaption>Video</figcaption>
            </figure>
          </div> 
        </article>


 -->

        
      





        <article class="entry" data-tags="Robotics RL">
          <header>
            <h3 class="entry-title">Learning Robot Tasks From Videos</h3>
            <p class="entry-meta"><em>RL and IL, Open AI Gym, Transformers, ManiSkill2 dataset</em></p>
          </header>
          <p>Studied manipulator control using reinforcement and imitation learning via MLPs, CNNs, and transformers on the ManiSkill2 dataset. Mitigated covariate shift in the Franka Emika Panda Arm‚Äôs pick-and-place task through an encoder transformer for behavior cloning, achieving a 20% success rate with imitation learning, with 80% showing either correct picking or placing. Implemented PPO-based reinforcement learning control, achieving 100% task success for a selected task.</p>
          
          
          
          <div class="media-row">
            <figure>
              <iframe src="https://drive.google.com/file/d/1ST4gQUVq2VMVshvh5eF5Bj4kHOdr9UXL/preview" width="300" height="200" loading="lazy" title="Manipulator project video" allow="autoplay"></iframe>
              <figcaption>Video</figcaption>
            </figure>
        
          </div>

          <div class="resources" aria-label="Resources">
            <a class="resource" href="https://drive.google.com/drive/folders/1T5tiQO0bLbTUItd1noYc_CKOu-KPxBBm" target="_blank" rel="noopener" aria-label="Open project report and materials"><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 3v2h3.59L7 15.59 8.41 17 19 6.41V10h2V3z"/><path d="M5 5h5V3H3v7h2z"/></svg><span>Report</span></a>
          </div>



        </article>

        <article class="entry" data-tags="CV Robotics">
          <header>
            <h3 class="entry-title">Road Image Segmentation with Supervised & Unsupervised Methods</h3>
            <p class="entry-meta"><em>Supervised & Unsupervised ML, CARLA dataset</em></p>
          </header>
          <p>Deployed supervised and unsupervised methods like K-Means, DB Scan, Gaussian Mixture Models, and U-NET for segmenting road images from the CARLA dataset. Achieved a 95% Dice Score using U-NET for instance segmentation and a Silhouette Coefficient of 0.5 with K-Means and Gaussian Mixture Models.</p>
          <div class="media-row">
            <figure>
              <img src="images/Actual Image.png" srcset="images/Actual Image.png 300w, images/Actual Image.png 600w" sizes="(max-width: 700px) 45vw, 300px" alt="Example of a road image from the CARLA dataset" loading="lazy" decoding="async">
              <figcaption>Actual Image</figcaption>
            </figure>
            <figure>
              <img src="images/Actual Mask.png" srcset="images/Actual Mask.png 300w, images/Actual Mask.png 600w" sizes="(max-width: 700px) 45vw, 300px" alt="Ground-truth mask for the road image" loading="lazy" decoding="async">
              <figcaption>Ground-truth Mask</figcaption>
            </figure>
            <figure>
              <img src="images/Predicted Mask.png" srcset="images/Predicted Mask.png 300w, images/Predicted Mask.png 600w" sizes="(max-width: 700px) 45vw, 300px" alt="Predicted segmentation mask" loading="lazy" decoding="async">
              <figcaption>Predicted Mask</figcaption>
            </figure>
          </div>
          <div class="resources">
            <a class="resource" href="https://drive.google.com/file/d/1VQ_T2tJRXxCKPTw_OntqRXtBdwHXfxGX/preview" target="_blank" rel="noopener" aria-label="Open project report"><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 3v2h3.59L7 15.59 8.41 17 19 6.41V10h2V3z"/><path d="M5 5h5V3H3v7h2z"/></svg><span>Report</span></a>
          </div>
        </article>

        <article class="entry" data-tags="Robotics SLAM">
          <header>
            <h3 class="entry-title">SLAM using TurtleBot3 and ROS 2</h3>
            <p class="entry-meta"><em>Python, ROS 2, SLAM</em></p>
          </header>
          <p>Developed a 2D map by teleoperating the robot in both physical and Gazebo environments, utilizing the Cartographer algorithm. Tuned ROS2 SLAM parameters to ensure the robot could smoothly traverse the map and autonomously navigate to three randomly provided locations within a 7x6 feet arena with barriers.</p>
         
        

          <div class="media-row">
            <figure>
              <iframe src="https://drive.google.com/file/d/1UNlL5XAsnarwNPedrqDOrBz3KvxB1QFK/preview" width="300" height="200" loading="lazy" title="SLAM hardware results" allow="autoplay"></iframe>
              <figcaption>Hardware</figcaption>
            </figure>
            <figure>
              <iframe src="https://drive.google.com/file/d/1UNWeqgoI5wbZBJh4Q5skkoUk7QLhszl_/preview" width="300" height="200" loading="lazy" title="SLAM simulation results" allow="autoplay"></iframe>
              <figcaption>Simulation</figcaption>
            </figure>
          </div>


        </article>

        <article class="entry" data-tags="RL">
          <header>
            <h3 class="entry-title">CartPole Control using Deep Reinforcement Learning</h3>
            <p class="entry-meta"><em>DQN, DDQN, Dueling DDQN, CNN-DQN, PPO</em></p>
          </header>
          <p>Conducted a comparative study of Deep Q-learning, its variations (DQN, DDQN, Dueling DDQN, CNN-DQN), and Proximal Policy Optimization (PPO) on the classical CartPole control problem using OpenAI Gym. Results showed that PPO and DDQN achieved perfect scores of 500 across 100 episodes, outperforming DQN variations. CNN-DQN struggled with convergence, while PPO demonstrated superior stability by preventing drastic policy changes. The study provided valuable insights into the performance differences of policy-based and Q-learning methods for reinforcement learning tasks.</p>
   
          <div class="media-row">
            <figure>
              <iframe width="300" height="200" src="https://www.youtube.com/embed/aSomRKi8ldk" loading="lazy" title="CartPole video" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"></iframe>
              <figcaption>Video</figcaption>
            </figure>
          </div>
          <div class="resources">
            <a class="resource" href="https://drive.google.com/file/d/1pXP1s9iPr3aNRjS65cGPXwxlBu6W9ra-/preview" target="_blank" rel="noopener" aria-label="Open project report"><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 3v2h3.59L7 15.59 8.41 17 19 6.41V10h2V3z"/><path d="M5 5h5V3H3v7h2z"/></svg><span>Report</span></a>
          </div>
        </article>

        <article class="entry" data-tags="Robotics RL IL">
          <header>
            <h3 class="entry-title">Legged and Humanoid Robot Control in MuJoCo</h3>
            <p class="entry-meta"><em>Reinforcement & Imitation Learning</em></p>
          </header>
          <p>Implemented legged robot control with RL, curriculum learning, and custom reward functions to make a quadruped robot move over obstacles with increasing height. Implemented two walking modes (normal and stealthy) for a humanoid robot using imitation learning and reference state initialization.</p>
          
          
 
            <div class="media-row">
              <figure>
                <iframe src="https://drive.google.com/file/d/1I58gJm3NWNfTmiC7EQd0LxJidSJRdBum/preview" width="300" height="200" loading="lazy" title="MuJoCo project video" allow="autoplay"></iframe>
                <figcaption>Video</figcaption>
              </figure>
            </div>
          



        </article>

        <article class="entry" data-tags="RL IL">
          <header>
            <h3 class="entry-title">Diffusion Model as Robot Action Policy</h3>
            <p class="entry-meta"><em>IL, Robot Task Planning, Diffusion</em></p>
          </header>
          <p>Implemented a diffusion model to imitate demonstrations and model action distribution given states, obtaining 100% accuracy in guiding a point agent to push a T-shaped block onto a T-shaped outline.</p>
        
            <div class="media-row">
              <figure>
                <iframe src="https://drive.google.com/file/d/1ShYIWfRgEG_byB5lhU0caR3iy0hzhxL_/preview" width="200" height="200" loading="lazy" title="GIF 1" allow="autoplay"></iframe>
                <figcaption>GIF 1</figcaption>
              </figure>
              <figure>
                <iframe src="https://drive.google.com/file/d/1FnWnpkCPviuyjgxSR91XiT4lEQY6ZkI5/preview" width="200" height="200" loading="lazy" title="GIF 2" allow="autoplay"></iframe>
                <figcaption>GIF 2</figcaption>
              </figure>
              <figure>
                <iframe src="https://drive.google.com/file/d/1zlsUKLyPN4H47rNCSMEwWLrovdPQuLn9/preview" width="200" height="200" loading="lazy" title="GIF 3" allow="autoplay"></iframe>
                <figcaption>GIF 3</figcaption>
              </figure>
            </div>
     
        </article>

        <article class="entry" data-tags="CV">
          <header>
            <h3 class="entry-title">Pedestrian Behaviour Classification</h3>
            <p class="entry-meta"><em>Detection + Transfer Learning (VGG16)</em></p>
          </header>
          <p>Prepared a pedestrian image dataset by combining data from various sources and annotating pedestrian state as distracted or non-distracted. Detected pedestrians with 100% accuracy via FRCNN and identified distraction with 90% accuracy via transfer learning with VGG16.</p>
          <div class="media-row">
            <figure>
              <img src="images/ped1.png" srcset="images/ped1.png 300w, images/ped1.png 600w" sizes="(max-width: 700px) 45vw, 300px" alt="Pedestrian detection bounding boxes" loading="lazy" decoding="async">
              <figcaption>Detection</figcaption>
            </figure>
            <figure>
              <img src="images/ped2.png" srcset="images/ped2.png 300w, images/ped2.png 600w" sizes="(max-width: 700px) 45vw, 300px" alt="Pedestrian using mobile phone" loading="lazy" decoding="async">
              <figcaption>Use of Mobile</figcaption>
            </figure>
            <figure>
              <img src="images/ped3.png" srcset="images/ped3.png 300w, images/ped3.png 600w" sizes="(max-width: 700px) 45vw, 300px" alt="Detecting distraction state of pedestrians" loading="lazy" decoding="async">
              <figcaption>Distraction Classification</figcaption>
            </figure>
          </div>
          <div class="resources">
            <a class="resource" href="https://drive.google.com/file/d/1ZwmTaNE6NLHYxsfXNvn2XleH-8ChQ3_c/preview" target="_blank" rel="noopener" aria-label="Open project report"><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 3v2h3.59L7 15.59 8.41 17 19 6.41V10h2V3z"/><path d="M5 5h5V3H3v7h2z"/></svg><span>Report</span></a>
          </div>
        </article>

        <article class="entry" data-tags="Robotics">
          <header>
            <h3 class="entry-title">Autonomous Line Following Ball Throwing Robot</h3>
            <p class="entry-meta"><em>Arduino, IR sensors, encoders, differential drive, PID</em></p>
          </header>
          <p>Developed a robot using Arduino, IR sensors, self-fabricated motor drivers, and regulators with discrete components. Implemented differential drive for mobility and a flywheel mechanism for shooting. Calibrated motor encoders to ensure accurate odometry readings, enabling the robot to autonomously traverse a 4x8 feet arena and drop balls into four hoops within three minutes, guided by line-following and PID control.</p>
        
            <div class="media-row">
              <figure>
                <iframe width="300" height="200" src="https://www.youtube.com/embed/aBi1eaDylxo?start=6" loading="lazy" title="Line following robot video" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"></iframe>
                <figcaption>Video</figcaption>
              </figure>
            </div>
     
        </article>

        <article class="entry" data-tags="C++">
          <header>
            <h3 class="entry-title">HAWAI FIRING: Shooting Game (C++)</h3>
            <p class="entry-meta"><em>SDL 2.0 ¬∑ OOP design ¬∑ UML</em></p>
          </header>
          <p>Developed a bubble shooting game using C++ and the SDL 2.0 library to practice OOP design principles, clean code practices, and maintainability through UML diagrams. Created the game from scratch, including multiple levels, menu screens, saving mechanisms, and object graphics. Implemented game physics using kinematic principles and collision detection strategies.</p>
        
            <div class="media-row">
              <figure>
                <iframe src="https://drive.google.com/file/d/1T82pM_7SujElT25AcSfwum1NO_sINBIn/preview" width="300" height="200" loading="lazy" title="C++ game video" allow="autoplay"></iframe>
                <figcaption>Video</figcaption>
              </figure>
            </div>
  
      </section>


<section id="reflections" class="card" aria-labelledby="reflections-heading">
  <h2 id="reflections-heading">Research Paper Reflections</h2>
  <p>
    I have had <strong>opportunities</strong> to read and reflect on a number of
    state-of-the-art papers recently. I‚Äôm documenting my reviews and reflections
    as concise write-ups and presentation slides. I also plan to convert this
    section into a blog and implement selected findings in code where feasible.
  </p>

  <div class="media-row" style="align-items:center; gap:1rem;">
    <button type="button" class="resource" aria-disabled="true" disabled>
      <svg viewBox="0 0 24 24" aria-hidden="true">
        <path d="M14 3v2h3.59L7 15.59 8.41 17 19 6.41V10h2V3z"/>
        <path d="M5 5h5V3H3v7h2z"/>
      </svg>
      <span>Coming Soon</span>
    </button>
    <!-- Optional placeholder link you can enable later:
    <a class="resource" href="/reflections" target="_blank" rel="noopener">
      <svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 3v2h3.59L7 15.59 8.41 17 19 6.41V10h2V3z"/><path d="M5 5h5V3H3v7h2z"/></svg>
      <span>Open Reflections Blog</span>
    </a>
    -->
  </div>

  <!-- Placeholder grid for future posts -->
  <!--
  <div class="media-row">
    <figure>
      <img src="images/reflection-placeholder.png" alt="Placeholder for paper reflection card" loading="lazy" decoding="async">
      <figcaption>Reflection #1 ‚Äî Title TBD</figcaption>
    </figure>
    <figure>
      <img src="images/reflection-placeholder.png" alt="Placeholder for paper reflection card" loading="lazy" decoding="async">
      <figcaption>Reflection #2 ‚Äî Title TBD</figcaption>
    </figure>
  </div>
  -->
</section>

          

      <section id="internships" class="card" aria-labelledby="internships-heading">
        <h2 id="internships-heading">Work Experience</h2>

        <article class="entry" data-tags="Robotics">
          <header>
            <h3 class="entry-title">Software Engineer (March 2025 - Present)</h3>
            <p class="entry-meta"><em>Borderless, Remote (Freelance)</em></p>
          </header>
          <p>Led ideation to translate client needs into a scalable web solution, developed with Python (Flask), HTML, CSS, JavaScript, and deployed
            on AWS Lightsail. Engineered a Mapbox-based interactive globe enabling filterable data visualization to drive thematic storytelling.
            Working on the backend to support content automation and transition from manual Excel-based workflows to a database-driven system.</p>
          
        </article>


<!--  -->


<article class="entry" data-tags="Robotics">
  <header>
    <h3 class="entry-title">Product and AI Engineer (September 2024 - November 2024)</h3>
    <p class="entry-meta"><em>Reflection AI, Singapore (Remote) </em></p>
  </header>
  <p>Contributed to cross-functional planning across AI, product, and UI/UX to support the company‚Äôs vision of building an AI app marketplace.</p>
  
</article>




<!--  -->


<!--  -->


<article class="entry" data-tags="Robotics">
  <header>
    <h3 class="entry-title">Summer Intern at EPIC Lab (May 2023 - August 2023)</h3>
    <p class="entry-meta"><em>Georgia Institute of Technology, Atlanta, GA, USA</em></p>
  </header>
  <p>Worked with a Ph.D. student to enhance the circuit and mechanical design quality of a hip exoskeleton, resolving electronic and mechanical design issues by cleaning up circuits, fabricating new PCBs, 3D-printing worn-out clippers, and reinforcing components to reduce vibrations and eliminate circuit failures. Concurrently conducted data collection, amassing 60 hours of respiratory and EMG data from human subject trials, required by lab researchers to assess metabolic costs and muscle activity.</p>
  <div class="media-row" style="display:flex; gap:1rem; flex-wrap:wrap;">
    <figure style="text-align:center; margin:0;">
      <img src="images/hip exo.jpg" 
           alt="Hip exoskeleton device" 
           loading="lazy" decoding="async"
           style="width:200px; height:300px; object-fit:cover; display:block;">
      <figcaption>Hip Exoskeleton</figcaption>
    </figure>
  
    <figure style="text-align:center; margin:0;">
      <img src="images/ankle exo.jpg" 
           alt="Ankle exoskeleton device" 
           loading="lazy" decoding="async"
           style="width:200px; height:300px; object-fit:cover; display:block;">
      <figcaption>Ankle Exoskeleton</figcaption>
    </figure>
  
    <figure style="text-align:center; margin:0;">
      <iframe src="https://drive.google.com/file/d/1LpR5mht57LyxhikiUKvk_eSr1liwJkUG/preview" 
              loading="lazy" title="Internship video" allow="autoplay"
              style="width:200px; height:300px; border:0; display:block;"></iframe>
      <figcaption>Video</figcaption>
    </figure>
  </div>
  





  
  <div class="resources">
    <a class="resource" href="https://drive.google.com/file/d/1P_fqq2kKkgicb0TBy5I_YJrWGEyCSGdo/view?usp=sharing" target="_blank" rel="noopener" aria-label="Open internship report in Google Drive"><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 3v2h3.59L7 15.59 8.41 17 19 6.41V10h2V3z"/><path d="M5 5h5V3H3v7h2z"/></svg><span>Internship Report</span></a>
  </div>
</article>




<!--  -->

<!--  -->



<article class="entry" data-tags="Robotics">
  <header>
    <h3 class="entry-title">Robotics Lab Engineer (July 2021 - December 2021)</h3>
    <p class="entry-meta"><em>Habib University, Karachi, Pakistan</em></p>
  </header>
  <p>Spearheaded the establishment of a new robotics lab by creating an experiment bench with PhantomX
    manipulators and Intel RealSense D435i. Enabled students to test their robots for a robo soccer project by engineering a 6x8 feet robot tracking
    arena using Python, C, and camera vision.</p>
  
</article>




<!--  -->

      </section>

      <section id="teaching" class="card" aria-labelledby="teaching-heading">
        <h2 id="teaching-heading">Teaching Experience</h2>



        
        
        
    
<article class="entry" data-tags="Robotics">
  <header>
    <h3 class="entry-title">Graduate Teaching Assistant (January 2023 - May 2024)</h3>
    <p class="entry-meta"><em>Georgia Institute of Technology Atlanta, GA, USA</em></p>
  </header>
  <p>Course Assisted: Physics 2211 - Matter and Interactions (Spring 2023, Fall 2023 & Spring 2024)</p>
    <p>Conducted bi-weekly lab experiment and recitation sessions for an average class size of 60 students. Consistently rated 4‚Äì5/5 in student evaluations across all metrics, reflecting strong teaching impact.</p>

</article>



<article class="entry" data-tags="Robotics">
  <header>
    <h3 class="entry-title">Lab Instructor (July 2021 - December 2021)</h3>
    <p class="entry-meta"><em>Habib University, Karachi, Pakistan</em></p>
  </header>
  <p>Designed and instructed labs in Physics 101 and Basic Electronics, strengthening students‚Äô grasp of
    fundamental physical principles and electronic circuits.</p>
  
</article>




<article class="entry" data-tags="Robotics">
  <header>
    <h3 class="entry-title">Undergraduate Teaching Assistant/Peer Tutor (January 2019 - May 2021)</h3>
    <p class="entry-meta"><em>Habib University, Karachi, Pakistan</em></p>
  </header>
  <p>Courses Assisted: Calculus II (Spring 2019), Engineering Mathematics (Fall 2019), Electrical Machines
    (Spring & Fall 2020), Mechanics & Thermodynamics (Spring 2020), Probability & Statistics (Spring
    & Fall 2020), Electric Network Analysis (Spring 2021)
    </p>
    <p>Managed teaching responsibilities for classes of 30‚Äì60 students, encompassing grading, assignment
      development, recitation and revision sessions, and individual tutoring support.</p>
  
</article>

        <div class="media-row">
          <figure>
            <img src="images/gta lab.png" alt="GTA Lab Picture" style="width:400px;height:auto;" loading="lazy">
            <figcaption>GTA Lab</figcaption>
          </figure>
        </div>
      </section>

      <section id="education" class="card" aria-labelledby="education-heading">
        <h2 id="education-heading">Education</h2>

        <article class="entry" data-tags="Education">
          <header>
            <h3 class="entry-title">Georgia Institute of Technology</h3>
            <p class="entry-meta"><em>M.S. in Robotics</em> | Janunary 2023 ‚Äì May 2024 | CGPA: 4.00/4.00</p>
          </header>
          <p>Coursework: Introduction to Robotics Research, Robotics, Machine Learning, Deep Learning, Deep Reinforcement Learning for Intelligent Control, Machine Vision, Linear Control Systems, Artificial Intelligence, Robotics Professional Prep Seminar 1‚Äì3, Robotics Capstone Project 1 & 2</p>
          <div class="media-row">
            <figure>
              <img src="images/MS convocation.jpeg" alt="MS Convocation" style="width:400px;height:450px;" loading="lazy">
              <figcaption>Convocation</figcaption>
            </figure>
           
          </div>

          <div class="resources">
            <a class="resource" href="https://drive.google.com/file/d/1GzxAIHD6blCczRu50SW8KY1RZOpnG6RF/view?usp=sharing" target="_blank" rel="noopener" aria-label="Open MS degree certificate"><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 3v2h3.59L7 15.59 8.41 17 19 6.41V10h2V3z"/><path d="M5 5h5V3H3v7h2z"/></svg><span>MS Degree</span></a>
            <a class="resource" href="https://drive.google.com/file/d/1TBAg6S4ulhyARmhU4gbGXx6fyZ4A_Xe8/view?usp=sharing" target="_blank" rel="noopener" aria-label="Open MS transcript"><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 3v2h3.59L7 15.59 8.41 17 19 6.41V10h2V3z"/><path d="M5 5h5V3H3v7h2z"/></svg><span>MS Transcript</span></a>
          </div>
        </article>

        <article class="entry" data-tags="Education">
          <header>
            <h3 class="entry-title">Habib University, Karachi, Pakistan</h3>
            <p class="entry-meta"><em>B.S. in Electrical Engineering</em> | Minors: Physics and Mathematics | August 2017 ‚Äì June 2021 | CGPA: 3.82/4.00 | Major Rank: 03/37</p>
          </header>
          <p>Selected Coursework: Feedback and Control Theory, Computer Vision, Mobile Robotics, Instrumentation,
            Linear Algebra, Probability and Statistics, Calculus, Engineering Mathematics, Engineering Design</p>
          <div class="media-row">
            <figure>
              <img src="images/BS Convocation.jpg" alt="BS Convocation" style="width:300px;height:auto;" loading="lazy">
              <figcaption>Convocation</figcaption>
            </figure>
            
          </div>
          <div class="media-row">
           
            <figure>
              <img src="images/best fyp.jpg" srcset="images/best fyp.jpg 300w, images/best fyp.jpg 600w" sizes="(max-width: 700px) 45vw, 300px" alt="Best capstone project certificate" loading="lazy" decoding="async">
              <figcaption>Best Capstone Project</figcaption>
            </figure>
            <figure>
              <img src="images/outstanding TA.jpg" srcset="images/outstanding TA.jpg 300w, images/outstanding TA.jpg 600w" sizes="(max-width: 700px) 45vw, 300px" alt="Outstanding Teaching Assistant certificate" loading="lazy" decoding="async">
              <figcaption>Outstanding TA</figcaption>
            </figure>
            <figure>
              <img src="images/double minor completion.jpg" srcset="images/double minor completion.jpg 300w, images/double minor completion.jpg 600w" sizes="(max-width: 700px) 45vw, 300px" alt="Double minor completion certificate" loading="lazy" decoding="async">
              <figcaption>Double Minor</figcaption>
            </figure>
          </div>
          <div class="resources">
            <a class="resource" href="https://drive.google.com/file/d/1Xv9-x0FBuS84JGPubWx2u-x_ryin1FXS/view?usp=sharing" target="_blank" rel="noopener" aria-label="Open BS degree certificate"><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 3v2h3.59L7 15.59 8.41 17 19 6.41V10h2V3z"/><path d="M5 5h5V3H3v7h2z"/></svg><span>BS Degree</span></a>
            <a class="resource" href="https://drive.google.com/file/d/1Xv5OevGZpx3fkcbLnebX85Wbnm9YK-sG/view?usp=sharing" target="_blank" rel="noopener" aria-label="Open BS transcript"><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 3v2h3.59L7 15.59 8.41 17 19 6.41V10h2V3z"/><path d="M5 5h5V3H3v7h2z"/></svg><span>BS Transcript</span></a>
          </div>
        </article>
      </section>


      <footer class="site-footer">
        <p>Code borrowed from <a href="https://github.com/jonbarron/jonbarron_website" target="_blank" rel="noopener">source code</a>. ¬© <span id="year"></span> Waleed Bin Khalid.</p>
      </footer>
    </main>
  </div>

  <button class="back-to-top" aria-label="Back to top">‚Üë</button>

  <div id="modal" class="modal" aria-hidden="true" role="dialog" aria-modal="true" aria-label="Media viewer">
    <div class="modal__backdrop" data-close></div>
    <div class="modal__dialog" role="document">
      <button class="modal__close" aria-label="Close" data-close>‚úï</button>
      <div class="modal__content" id="modal-content"></div>
    </div>
  </div>
  <script>
    (function() {
      // Remove existing modal click handlers by cloning media-row images
      document.querySelectorAll('.media-row img').forEach(function(img) {
        var clone = img.cloneNode(true);
        if (img.parentNode) {
          img.parentNode.replaceChild(clone, img);
        }
      });

      function openImageInNewTab(ev) {
        var img = ev.currentTarget;
        var url = img.currentSrc || img.src;
        if (!url) return;
        ev.preventDefault();
        ev.stopPropagation();
        window.open(url, '_blank', 'noopener');
      }

      // Make every image clickable to open in a new tab
      document.querySelectorAll('img').forEach(function(img) {
        img.style.cursor = 'pointer';
        img.addEventListener('click', openImageInNewTab, { passive: false });
      });
    })();
  </script>
  </body>
</html>
